# webcrawler

目标：抓取百度百科词条，抽取版本信息、定义段落等。

实现：

1.爬虫是io密集型的，因此采用了多线程构建程序。经典的多线程模式——生产者-消费者模型。

2.百度百科有反爬虫，通常的在user agent上变换的小手段，在高请求频率的情况下仍然会被ban。

3.从西刺代理上抓取http代理服务器。这个网站现在已经关闭了。这些代理都很不稳定，因此采用策略每间隔一定时间，检查一下代理是否可用，维护了一个代理池。

4.采用多线程+代理服务器之后，制约抓取速度的就是pc的解析速度了。基本可以达到百万条/天的速度。
